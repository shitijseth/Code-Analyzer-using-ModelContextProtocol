{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LI7huTtVxHmp",
        "outputId": "1b6e7277-9eb8-4b86-c49c-13124f534424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mcp in /usr/local/lib/python3.11/dist-packages (1.4.1)\n",
            "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.11/dist-packages (from mcp) (4.8.0)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.11/dist-packages (from mcp) (0.4.0)\n",
            "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.11/dist-packages (from mcp) (0.28.1)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from mcp) (2.8.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from mcp) (2.10.6)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from mcp) (2.2.1)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.11/dist-packages (from mcp) (0.46.1)\n",
            "Requirement already satisfied: uvicorn>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from mcp) (0.34.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio>=4.5->mcp) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=4.5->mcp) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio>=4.5->mcp) (4.12.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->mcp) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27->mcp) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27->mcp) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.2->mcp) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.2->mcp) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings>=2.5.2->mcp) (1.0.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.23.1->mcp) (8.1.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install mcp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mcp.server.fastmcp import FastMCP\n",
        "\n",
        "# Initialize the MCP client\n",
        "client = FastMCP(debug=True)"
      ],
      "metadata": {
        "id": "7sPVLhp6xQqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the GitHub MCP server\n",
        "client.connect('github_server')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "RAjIXWiixQtx",
        "outputId": "b3331ea9-43a3-4cf8-9c8a-652327a470ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'FastMCP' object has no attribute 'connect'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b7c19a2b3526>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Connect to the GitHub MCP server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'github_server'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'FastMCP' object has no attribute 'connect'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_repository(owner, repo):\n",
        "\n",
        "    response = client.call('github_server', 'get_repo_content', {'owner': owner, 'repo': repo})\n",
        "    return response"
      ],
      "metadata": {
        "id": "eZbQ2vfc0W7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O5jB08m80W4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mcp.server import McpServer, McpHandler\n",
        "import requests\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load an open source LLM for text generation.\n",
        "# Here we use GPT-J 6B; if resources are limited, you could use a smaller model like GPT-Neo.\n",
        "try:\n",
        "    llm = pipeline(\"text-generation\", model=\"EleutherAI/gpt-j-6B\", device=0)\n",
        "except Exception as e:\n",
        "    # Fallback to CPU if GPU is not available or model loading fails.\n",
        "    llm = pipeline(\"text-generation\", model=\"EleutherAI/gpt-j-6B\", device=-1)\n",
        "print(\"LLM loaded successfully.\")\n",
        "\n",
        "class MyMcpHandler(McpHandler):\n",
        "    def get_methods(self):\n",
        "\n",
        "        return {\n",
        "            'analyze_repo': self.analyze_repo,\n",
        "            'ask_repo_question': self.ask_repo_question,\n",
        "        }\n",
        "\n",
        "    def analyze_repo(self, params):\n",
        "\n",
        "        owner = params.get('owner')\n",
        "        repo = params.get('repo')\n",
        "        if not owner or not repo:\n",
        "            return \"Error: Missing 'owner' or 'repo' parameters.\"\n",
        "\n",
        "        # Use GitHub API to fetch repository contents.\n",
        "        url = f\"https://api.github.com/repos/{owner}/{repo}/contents\"\n",
        "        response = requests.get(url)\n",
        "        if response.status_code != 200:\n",
        "            return f\"Error: Unable to fetch repository (Status code: {response.status_code}).\"\n",
        "\n",
        "        contents = response.json()\n",
        "        analysis_results = []\n",
        "        for item in contents:\n",
        "            # Check for Python files for a simple analysis.\n",
        "            if item['type'] == 'file' and item['name'].endswith('.py'):\n",
        "                analysis_results.append(\n",
        "                    f\"File '{item['name']}' might benefit from improved error handling and better comments.\"\n",
        "                )\n",
        "        if not analysis_results:\n",
        "            analysis_results.append(\"No Python files found for analysis.\")\n",
        "        return analysis_results\n",
        "\n",
        "    def ask_repo_question(self, params):\n",
        "\n",
        "        owner = params.get('owner')\n",
        "        repo = params.get('repo')\n",
        "        question = params.get('question')\n",
        "        if not owner or not repo or not question:\n",
        "            return \"Error: Missing one or more parameters: 'owner', 'repo', 'question'.\"\n",
        "\n",
        "        # Fetch repository contents.\n",
        "        url = f\"https://api.github.com/repos/{owner}/{repo}/contents\"\n",
        "        response = requests.get(url)\n",
        "        if response.status_code != 200:\n",
        "            return f\"Error: Unable to fetch repository contents (Status code: {response.status_code}).\"\n",
        "\n",
        "        contents = response.json()\n",
        "        code_aggregate = \"\"\n",
        "        # Iterate through each item to fetch code from Python files.\n",
        "        for item in contents:\n",
        "            if item['type'] == 'file' and item['name'].endswith('.py'):\n",
        "                download_url = item.get('download_url')\n",
        "                if download_url:\n",
        "                    file_resp = requests.get(download_url)\n",
        "                    if file_resp.status_code == 200:\n",
        "                        code_aggregate += f\"\\n\\n# File: {item['name']}\\n\"\n",
        "                        code_aggregate += file_resp.text\n",
        "                    else:\n",
        "                        code_aggregate += f\"\\n\\n# File: {item['name']} - Unable to fetch file content.\\n\"\n",
        "        if not code_aggregate:\n",
        "            code_aggregate = \"No Python files found in the repository.\"\n",
        "\n",
        "        # Construct a prompt that includes the full code and the user's question.\n",
        "        prompt = (\n",
        "            f\"Repository {owner}/{repo} code:\\n\"\n",
        "            f\"{code_aggregate}\\n\\n\"\n",
        "            f\"Based on the code above, answer the following question: {question}\\n\"\n",
        "            \"Provide clear, detailed analysis and suggestions.\"\n",
        "        )\n",
        "        # Generate an answer using the LLM.\n",
        "        try:\n",
        "            output = llm(prompt, max_length=10000, do_sample=True, temperature=0.75)\n",
        "            answer = output[0]['generated_text']\n",
        "        except Exception as e:\n",
        "            answer = f\"LLM error: {str(e)}\"\n",
        "        return answer\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize and start the MCP server with our custom handler.\n",
        "    server = McpServer(handler=MyMcpHandler())\n",
        "    print(\"Starting MCP server on port 5000...\")\n",
        "    server.start(port=5000)\n"
      ],
      "metadata": {
        "id": "ovObHXI20W19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Add UI to ask more questions and asking more questions and more models\n",
        "Apply MCP to other use-cases"
      ],
      "metadata": {
        "id": "u8zLsZ8JM-MM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GIXcKQe-Yloh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test setup"
      ],
      "metadata": {
        "id": "VVtO3uTDS6Ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mcp.server.fastmcp import FastMCP\n",
        "\n",
        "mcp = FastMCP(\"Echo\", debug=True)\n",
        "\n",
        "@mcp.resource(\"echo://{message}\")\n",
        "def echo_resource(message: str) -> str:\n",
        "    \"\"\"Echo a message as a resource\"\"\"\n",
        "    return f\"Resource echo: {message}\"\n",
        "\n",
        "\n",
        "@mcp.tool()\n",
        "def echo_tool(message: str) -> str:\n",
        "    \"\"\"Echo a message as a tool\"\"\"\n",
        "    return f\"Tool echo: {message}\"\n",
        "\n",
        "\n",
        "@mcp.prompt()\n",
        "def echo_prompt(message: str) -> str:\n",
        "    \"\"\"Create an echo prompt\"\"\"\n",
        "    return f\"Please process this message: {message}\""
      ],
      "metadata": {
        "id": "Oh3cnpOxxVNm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}